import DataFromInternet, DB, Utils, Algorithms, DataFromInternet, Tree, Twitter, Utils, Algorithms, DB, pandas

# from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm
# from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
# from sklearn import decomposition, ensemble
#
# import pandas, xgboost, numpy, textblob, string
# from keras.preprocessing import text, sequence
# from keras import layers, models, optimizers


# data = open('./data/text_examples.txt', encoding="utf-8").read()
# labels, texts = [],[]
# for i, line in enumerate(data.split("\n")):
#     content = line.split()
#     labels.append(content[0])
#     texts.append(content[1:])
#
# # create a dataframe using texts and lables
# trainDF = pandas.DataFrame()
# trainDF['text'] = texts
# trainDF['label'] = labels
#
#
# # split the dataset into training and validation datasets
# train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'])
#
# # label encode the target variable
# encoder = preprocessing.LabelEncoder()
# train_y = encoder.fit_transform(train_y)
# valid_y = encoder.fit_transform(valid_y)
#
#




Algorithms.text_classification_with_naive_bayes('futbol americano')





